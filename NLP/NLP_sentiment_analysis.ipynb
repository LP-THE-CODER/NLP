{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7aCkEeDJlcF",
        "outputId": "48f0ebdc-833e-4887-b44b-bf044cd6bec9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# nltk is one of the most useful libraries when it comes to nlp\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFehT2wSJwB8"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Preprocessing and evaluation\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "\n",
        "# Models\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zXome8bKJ86i",
        "outputId": "39c57b3c-9122-4357-dc7d-f6f0589a9747"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('tripadvisor_hotel_reviews.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkmmS-HsJ-ES",
        "outputId": "68958891-4288-4883-ed60-1721183a808f"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "Wu2lbXrOK2ts",
        "outputId": "0aac23c2-1831-4712-921a-da8115c6c12c"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=df, x='Rating', palette='flare').set_title('Rating Distribution Across Dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HAGDHR3iK7xT",
        "outputId": "9ceb3931-4f11-4ae1-80c1-90cde1a20916"
      },
      "outputs": [],
      "source": [
        "# Length of word in sentence\n",
        "df['Length'] = df['Review'].apply(len)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "RJoxGoX8K-Z8",
        "outputId": "51b878d0-116a-4e5a-e829-4acad3c6e0b0"
      },
      "outputs": [],
      "source": [
        "sns.displot(data=df, x='Length', hue='Rating', palette='flare', kind='kde', fill=True, aspect=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "1pziW9uELBWD",
        "outputId": "6779ce19-2b67-4078-d8de-902e7f1fff0a"
      },
      "outputs": [],
      "source": [
        "g = sns.FacetGrid(data=df, col='Rating')\n",
        "g.map(plt.hist, 'Length', color='#973aa8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "q3WvgOPnLEPc",
        "outputId": "d905bdca-be3b-4f2e-ebab-45f4b7f62ebc"
      },
      "outputs": [],
      "source": [
        "sns.stripplot(data=df, x='Rating', y='Length', palette='flare', alpha=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SN1brnbhLHrD"
      },
      "outputs": [],
      "source": [
        "# Let's change the rating to be more general and easier to understand\n",
        "def rating(score):\n",
        "    if score > 3:\n",
        "        return 'Good'\n",
        "    elif score == 3:\n",
        "        return 'Netral'\n",
        "    else:\n",
        "        return 'Bad'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gCAVIGGLKzb"
      },
      "outputs": [],
      "source": [
        "df['Rating'] = df['Rating'].apply(rating)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OANR7K19LM4z",
        "outputId": "34f9c321-87a9-43bd-a8cd-cec4fa17ff2e"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tp5e3o-0LPay"
      },
      "outputs": [],
      "source": [
        "# Total word in dataset before cleaning\n",
        "length = df['Length'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7Bol0lSLRt6",
        "outputId": "154ff3a7-0f69-40c2-a71a-92a306f2189f"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "print('Original:')\n",
        "print(df['Review'][0])\n",
        "print()\n",
        "\n",
        "sentence = []\n",
        "for word in df['Review'][0].split():\n",
        "    stemmer = SnowballStemmer('english')\n",
        "    sentence.append(stemmer.stem(word))\n",
        "print('Stemming:')\n",
        "print(' '.join(sentence))\n",
        "print()\n",
        "\n",
        "sentence = []\n",
        "for word in df['Review'][0].split():\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    sentence.append(lemmatizer.lemmatize(word, 'v'))\n",
        "print('Lemmatization:')\n",
        "print(' '.join(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnSaWo0FL8Li"
      },
      "outputs": [],
      "source": [
        "def cleaning(text):\n",
        "    #remove punctuations and uppercase\n",
        "    clean_text = text.translate(str.maketrans('','',string.punctuation)).lower()\n",
        "\n",
        "    #remove stopwords\n",
        "    clean_text = [word for word in clean_text.split() if word not in stopwords.words('english')]\n",
        "\n",
        "    #lemmatize the word\n",
        "    sentence = []\n",
        "    for word in clean_text:\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        sentence.append(lemmatizer.lemmatize(word, 'v'))\n",
        "\n",
        "    return ' '.join(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0ZKVpevME97",
        "outputId": "ee6eef92-dd25-4ce1-c49a-434f9c58e1ce"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "df['Review'] = df['Review'].apply(cleaning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NF-ZGBItNQJU",
        "outputId": "9def14da-42ab-459f-eab8-6a49fb713a97"
      },
      "outputs": [],
      "source": [
        "df['Length'] = df['Review'].apply(len)\n",
        "new_length = df['Length'].sum()\n",
        "\n",
        "print('Total text length before cleaning: {}'.format(length))\n",
        "print('Total text length after cleaning: {}'.format(new_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veyUsN2GNSRD"
      },
      "outputs": [],
      "source": [
        "df.to_csv('cleaned_df.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "0v15cg59NVAL",
        "outputId": "04d8fb95-87be-4e6d-fed7-e2fa4d193de9"
      },
      "outputs": [],
      "source": [
        "# After cleaning, let's see the most common used word\n",
        "plt.figure(figsize=(20,20))\n",
        "wc = WordCloud(max_words=1000, min_font_size=10,\n",
        "                height=800,width=1600,background_color=\"white\", colormap='flare').generate(' '.join(df['Review']))\n",
        "\n",
        "plt.imshow(wc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Re0BVqGNgCa"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['Review'], df['Rating'], test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKH_Pgr1NiwM"
      },
      "outputs": [],
      "source": [
        "tfid = TfidfVectorizer()\n",
        "train_tfid_matrix = tfid.fit_transform(X_train)\n",
        "test_tfid_matrix = tfid.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZA6xqFcNk8t"
      },
      "outputs": [],
      "source": [
        "pickle.dump(tfid, open('tfidf.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3tTNEYQNoXy"
      },
      "outputs": [],
      "source": [
        "models = [DecisionTreeClassifier(),\n",
        "          RandomForestClassifier(),\n",
        "          SVC(),\n",
        "          LogisticRegression(max_iter=1000),\n",
        "          KNeighborsClassifier(),\n",
        "          BernoulliNB()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qKepsfWZC-w",
        "outputId": "44d9eb19-0a86-4d76-9e21-749a382cdfb7"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Assuming 'X_train' is your feature matrix obtained using TF-IDF\n",
        "# Assuming 'y_train' is your target variable for the training set\n",
        "\n",
        "# Vectorize the data\n",
        "vectorizer = TfidfVectorizer()\n",
        "train_tfid_matrix = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Initialize RandomForestClassifier with parallel processing\n",
        "rf_classifier = RandomForestClassifier(n_jobs=-1)\n",
        "\n",
        "# Perform cross-validation\n",
        "cross_val = cross_val_score(rf_classifier, train_tfid_matrix, y_train, scoring='accuracy',\n",
        "                            cv=StratifiedKFold(5)).mean()\n",
        "\n",
        "print(f\"Random Forest Classifier Accuracy: {cross_val:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-k_d1l7aGmy",
        "outputId": "297d250a-acca-435e-88c1-bc4076465b1a"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pydotplus\n",
        "from IPython.display import Image\n",
        "\n",
        "# Assuming 'X_train' is your feature matrix obtained using TF-IDF\n",
        "# Assuming 'y_train' is your target variable for the training set\n",
        "\n",
        "# Vectorize the data\n",
        "vectorizer = TfidfVectorizer()\n",
        "train_tfid_matrix = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Initialize DecisionTreeClassifier\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "\n",
        "# Perform cross-validation\n",
        "cross_val = cross_val_score(dt_classifier, train_tfid_matrix, y_train, scoring='accuracy',\n",
        "                            cv=StratifiedKFold(5)).mean()\n",
        "\n",
        "print(f\"Decision Tree Classifier Accuracy: {cross_val:.2f}\")\n",
        "\n",
        "# Fit the decision tree on the entire dataset\n",
        "dt_classifier.fit(train_tfid_matrix, y_train)\n",
        "\n",
        "# Export the decision tree to a Graphviz file\n",
        "dot_data = export_graphviz(dt_classifier, out_file=None,\n",
        "                           feature_names=vectorizer.get_feature_names_out(),\n",
        "                           class_names=dt_classifier.classes_,\n",
        "                           filled=True, rounded=True, special_characters=True)\n",
        "\n",
        "graph = pydotplus.graph_from_dot_data(dot_data)\n",
        "graph.write_png('decision_tree.png')\n",
        "\n",
        "# Display the decision tree image (requires Graphviz installed)\n",
        "Image(graph.create_png())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLPcNlnbaGef",
        "outputId": "9ac6fb55-aec6-4dcb-f665-2bc54365f728"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Assuming 'X_train' is your feature matrix obtained using TF-IDF\n",
        "# Assuming 'y_train' is your target variable for the training set\n",
        "\n",
        "# Vectorize the data\n",
        "vectorizer = TfidfVectorizer()\n",
        "train_tfid_matrix = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Initialize Support Vector Classifier\n",
        "svc_classifier = SVC()\n",
        "\n",
        "# Perform cross-validation\n",
        "cross_val = cross_val_score(svc_classifier, train_tfid_matrix, y_train, scoring='accuracy',\n",
        "                            cv=StratifiedKFold(5)).mean()\n",
        "\n",
        "print(f\"SVC Classifier Accuracy: {cross_val:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NosoyFFFepQQ",
        "outputId": "36327589-35a8-4ebf-e7d9-1f60aa2a25a6"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Assuming 'X_train' is your feature matrix obtained using TF-IDF\n",
        "# Assuming 'y_train' is your target variable for the training set\n",
        "\n",
        "# Vectorize the data\n",
        "vectorizer = TfidfVectorizer()\n",
        "train_tfid_matrix = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Initialize Logistic Regression\n",
        "logreg_classifier = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Perform cross-validation\n",
        "cross_val = cross_val_score(logreg_classifier, train_tfid_matrix, y_train, scoring='accuracy',\n",
        "                            cv=StratifiedKFold(5)).mean()\n",
        "\n",
        "print(f\"Logistic Regression Classifier Accuracy: {cross_val:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KU4pm9RvfEp6",
        "outputId": "0e772cd7-3a56-4a2e-e5d1-5c11749e4654"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Assuming 'X_train' is your feature matrix obtained using TF-IDF\n",
        "# Assuming 'y_train' is your target variable for the training set\n",
        "\n",
        "# Vectorize the data\n",
        "vectorizer = TfidfVectorizer()\n",
        "train_tfid_matrix = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Initialize KNN Classifier\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "\n",
        "# Perform cross-validation\n",
        "cross_val = cross_val_score(knn_classifier, train_tfid_matrix, y_train, scoring='accuracy',\n",
        "                            cv=StratifiedKFold(5)).mean()\n",
        "\n",
        "print(f\"KNN Classifier Accuracy: {cross_val:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmy4vZJ5fLWC",
        "outputId": "be237c53-4ac1-4ce7-ac4a-f6dbb13edf17"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Assuming 'X_train' is your feature matrix obtained using TF-IDF\n",
        "# Assuming 'y_train' is your target variable for the training set\n",
        "\n",
        "# Vectorize the data\n",
        "vectorizer = TfidfVectorizer()\n",
        "train_tfid_matrix = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Initialize Bernoulli Naive Bayes Classifier\n",
        "bernoulli_nb_classifier = BernoulliNB()\n",
        "\n",
        "# Perform cross-validation\n",
        "cross_val = cross_val_score(bernoulli_nb_classifier, train_tfid_matrix, y_train, scoring='accuracy',\n",
        "                            cv=StratifiedKFold(5)).mean()\n",
        "\n",
        "print(f\"Bernoulli Naive Bayes Classifier Accuracy: {cross_val:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOS7c0Vik2VP"
      },
      "outputs": [],
      "source": [
        "log = LogisticRegression(max_iter=1000)\n",
        "log.fit(train_tfid_matrix, y_train)\n",
        "\n",
        "pred = log.predict(test_tfid_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vG9ficppk--P"
      },
      "outputs": [],
      "source": [
        "pickle.dump(log, open('ml_model.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0KtCKrBlBfH",
        "outputId": "f7988510-8180-44f6-b3be-bab6db2084cf"
      },
      "outputs": [],
      "source": [
        "ml = pickle.load(open('ml_model.pkl','rb'))\n",
        "tfidf = pickle.load(open('tfidf.pkl','rb'))\n",
        "def ml_predict(text):\n",
        "    clean_text = cleaning(text)\n",
        "    tfid_matrix = tfidf.transform([clean_text])\n",
        "    pred_proba = ml.predict_proba(tfid_matrix)\n",
        "    idx = np.argmax(pred_proba)\n",
        "    pred = ml.classes_[idx]\n",
        "\n",
        "    return pred, pred_proba[0][idx]\n",
        "\n",
        "ml_predict('poor room service')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayxBDjvElEJo",
        "outputId": "7a70f421-d1ec-47e5-80c8-22053c1b3508"
      },
      "outputs": [],
      "source": [
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykJA4_a0lMuP",
        "outputId": "f77f2126-491f-44eb-803e-58b7d322dd9c"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=50000, oov_token='<OOV>')\n",
        "\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "# print(tokenizer.word_index)\n",
        "total_word = len(tokenizer.word_index)\n",
        "print('Total distinct words: {}'.format(total_word))\n",
        "\n",
        "train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "train_padded = pad_sequences(train_seq)\n",
        "\n",
        "test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "test_padded = pad_sequences(test_seq)\n",
        "\n",
        "# One hot encoding the label\n",
        "lb = LabelBinarizer()\n",
        "train_labels = lb.fit_transform(y_train)\n",
        "test_labels = lb.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDzITqiAlSgX"
      },
      "outputs": [],
      "source": [
        "pickle.dump(tokenizer, open('tokenizer.pkl', 'wb'))\n",
        "pickle.dump(lb, open('label.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMUtPKknlUvP",
        "outputId": "b77f9f34-a41d-4f95-aeb9-2e7df4a297db"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Embedding(total_word, 8),\n",
        "                                    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
        "                                    tf.keras.layers.Dropout(0.5),\n",
        "                                    tf.keras.layers.Dense(8, kernel_regularizer=l2(0.001),\n",
        "                                                          bias_regularizer=l2(0.001), activation='relu'),\n",
        "                                    tf.keras.layers.Dropout(0.5),\n",
        "                                    tf.keras.layers.Dense(3, activation='softmax')])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwaTbJw1latA",
        "outputId": "451348c4-c1ca-435f-c252-c176f5130298"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_padded, train_labels, epochs=3, validation_data=(test_padded, test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        },
        "id": "Pq4736dKoxCb",
        "outputId": "0e7db4a9-8fea-475d-b8e2-1d13336f895f"
      },
      "outputs": [],
      "source": [
        "metrics = pd.DataFrame(model.history.history)\n",
        "metrics[['accuracy', 'val_accuracy']].plot()\n",
        "metrics[['loss', 'val_loss']].plot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMRxuh3Wozpt",
        "outputId": "60c2c6fb-e84c-40e3-946a-f4e1f990b6af"
      },
      "outputs": [],
      "source": [
        "pred2 = model.predict(test_padded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVesXhYA0gqK"
      },
      "outputs": [],
      "source": [
        "true_labels = np.argmax(test_labels, axis=-1)\n",
        "pred_labels = np.argmax(pred2, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6nxfPNoo2TX",
        "outputId": "3082a4a5-bc30-4169-d3ba-f7c002d92935"
      },
      "outputs": [],
      "source": [
        "print(confusion_matrix(true_labels, pred_labels))\n",
        "print(classification_report(true_labels, pred_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "744lf5Zro4b3"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "def ml_predict(text):\n",
        "    clean_text = cleaning(text)\n",
        "    tfid_matrix = tfid.transform([clean_text])\n",
        "    pred = log.predict(tfid_matrix)[0]\n",
        "\n",
        "    return pred\n",
        "\n",
        "# Deep Neural Network\n",
        "def dl_predict(text):\n",
        "    clean_text = cleaning(text)\n",
        "    seq = tokenizer.texts_to_sequences([clean_text])\n",
        "    padded = pad_sequences(seq)\n",
        "\n",
        "    pred = model.predict(padded)\n",
        "    # Get the label name back\n",
        "    result = lb.inverse_transform(pred)[0]\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8X3Xik7pBm_",
        "outputId": "f85199b1-1974-4300-be0a-7b3dfcd700fc"
      },
      "outputs": [],
      "source": [
        "text = 'Such a comfy place to stay with the loved one'\n",
        "\n",
        "print('Prediction using Logistic Regression: {}'.format(ml_predict(text)))\n",
        "print('Prediction using DNN: {}'.format(dl_predict(text)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wejyDF3OpDwo",
        "outputId": "b6dc84bc-6ac8-4e53-e302-d596f3567558"
      },
      "outputs": [],
      "source": [
        "text2 = 'Awful room services and slow wifi connection'\n",
        "\n",
        "print('Prediction using Logistic Regression: {}'.format(ml_predict(text2)))\n",
        "print('Prediction using DNN: {}'.format(dl_predict(text2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMo6B9ZjpF3p",
        "outputId": "2d0382e3-563b-4b43-fd7d-73328a22bc2e"
      },
      "outputs": [],
      "source": [
        "text3 = 'Hard to get here but the scenery is wonderful'\n",
        "\n",
        "print('Prediction using Logistic Regression: {}'.format(ml_predict(text3)))\n",
        "print('Prediction using DNN: {}'.format(dl_predict(text3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYurI1fa0u_i",
        "outputId": "3e274a65-871b-48e9-b7c0-3e4b8457f765"
      },
      "outputs": [],
      "source": [
        "text4 = 'waste service'\n",
        "\n",
        "print('Prediction using Logistic Regression: {}'.format(ml_predict(text2)))\n",
        "print('Prediction using DNN: {}'.format(dl_predict(text2)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
